{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Web Scrape the IMBD Website with Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules for API calling and \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure we get English-translated titles from movies\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lists for storage of scraped data\n",
    "titles = []\n",
    "imdb_ids = []\n",
    "pg_ratings = []\n",
    "years = []\n",
    "runtimes = []\n",
    "genres = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "gross_us = []\n",
    "names = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79590c93caa4b469f6e82ce135de143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Download Progress:'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create for loop to iterate through each page containing 50 movies of the top 1000\n",
    "# sorted by US gross box office to get dataset with mostly American films\n",
    "# tqdm creates the progress bar for the web scrape\n",
    "for n in tqdm(range(1, 1000, 50), desc='Download Progress:'):\n",
    "    # Create an expression that represents each page for the iteration\n",
    "    url = 'https://www.imdb.com/search/title/?groups=top_1000&sort=boxoffice_gross_us,desc&start={}&ref_=adv_nxt'.format(n)\n",
    "    # The requests library makes a get request to the url for data, which is saved to results\n",
    "    results = requests.get(url, headers=headers)\n",
    "    # Create an instance of BeautifulSoup to parse results\n",
    "    soup = BS(results.text, \"html.parser\")\n",
    "    # Find the div container in the HTML that contains the wanted information.  \n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    # Use function to suspend execution of calling thread at random\n",
    "    time.sleep(random.randint(3, 12))\n",
    "\n",
    "    # for each container in the div container created above by Beautiful Soup\n",
    "    for div in movie_div:\n",
    "        # to get the titles, we use attribute notation to access the title contained as text in the <a> tag nested inside the <h3> tag \n",
    "        # dot notation only works with the first instance of the tag\n",
    "        title = div.h3.a.text\n",
    "        # we append the scraped title to the titles list through each iteration\n",
    "        titles.append(title)\n",
    "        # to get the IMDB id's, we use the find() method to find the first instance \n",
    "        imdb_id = div.find('img')['data-tconst']\n",
    "        imdb_ids.append(imdb_id)\n",
    "        # to scrape the year, we use the find() method to search nested inside the h3 tag to get the text inside the span tag with the class lister-item-year\n",
    "        year = div.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        # to scrape the pg rating, we use the find method again but create a condition in the case of blank values\n",
    "        pg_rating = div.find('span', class_='certificate').text if div.p.find('span', class_='certificate') else '--'\n",
    "        pg_ratings.append(pg_rating)\n",
    "        # to scrape the runtime, we use a similar method from above\n",
    "        runtime = div.find('span', class_='runtime').text if div.p.find('span', class_='runtime') else '--'\n",
    "        runtimes.append(runtime)\n",
    "        # to scrape the genres, we employed the same method\n",
    "        genre = div.find('span', class_='genre').text\n",
    "        genres.append(genre)\n",
    "        # to scrape the IMDB rating, we call the distinctive strong tag which wraps the desired text\n",
    "        imdb_rating = div.strong.text\n",
    "        imdb_ratings.append(imdb_rating)\n",
    "        # to scrape the etascore, we use a similar code as above\n",
    "        metascore = div.find('span', class_='metascore').text if div.find('span', class_='metascore') else '--'\n",
    "        metascores.append(metascore)\n",
    "        # to scrape the votes and gross us earnings, we use the find_all method, which finds all the instances of the span tag with the name attribute and value of nv\n",
    "        # if there is one item in the list, it represents the vote, and if there are two items, then we get the gross earning and return a string if it's empty to ensure all our lists are the same length to make the DataFrame\n",
    "        nv = div.find_all('span', attrs={'name': 'nv'})\n",
    "        vote = nv[0].text\n",
    "        votes.append(vote)\n",
    "        gross = nv[1].text if len(nv) > 1 else '--'\n",
    "        gross_us.append(gross)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas dataframe with the \n",
    "movies = pd.DataFrame({\n",
    "    'movie': titles, 'year' : years, 'pg_rating' : pg_ratings, 'imdb_id' : imdb_ids, 'runtime' : runtimes, 'genre' : genres, 'metascore' : metascores, 'imdb_rating' : imdb_ratings, 'votes' : votes, 'gross_us' : gross_us\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "movies['imdb_id'] = movies['imdb_id'].str.extract('(\\d+)').astype(int)\n",
    "# \n",
    "movies['year'] = movies['year'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "movies['runtime'] = movies['runtime'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "movies['metascore'] = movies['metascore'].str.rstrip()\n",
    "\n",
    "movies['metascore'] = pd.to_numeric(movies['metascore'], errors='coerce')\n",
    "\n",
    "movies['votes'] = movies['votes'].str.replace(',', '').astype(int)\n",
    "\n",
    "movies['gross_us'] = movies['gross_us'].map(lambda x: x.lstrip('$').rstrip('M'))\n",
    "movies['genre'] = movies['genre'].map(lambda x: x.strip('\\n').rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to a CSV file\n",
    "movies.to_csv('top_1000_by_us_box_office.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential webscrape \n",
    "https://www.imdb.com/search/title/?title_type=feature&num_votes=25000,&genres=action&sort=user_rating,desc&start=51&ref_=adv_nxt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
